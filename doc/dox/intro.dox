/**
 * \if LATMRG_DOC
 * \page lattice_back Theory on Lattices
 * 
 * This is the theory page available in LatticeTester. This page covers the
 * concept of lattices as well as a few algorithms very important in LatMRG.
 *
 * \else
 * \page a_intro Background
 *
 * This page contains a (not so brief) summary of the mathematical concepts
 * used in *LatticeTester*.
 * The library is intended to ease the computation of uniformity
 * measures (also called figures of merit) on lattices in the
 * \f$t\f$-dimensional the real space \f$\mathbb{R}^t\f$ that are contained in
 * \f$\mathbb{Z}^t\f$.
 * We therefore introduce here exactly what those lattices are
 * and part of the theory behind the implemented algorithms.
 *
 * \endif
 * \section lattices_def Lattices on the Integers
 *
 * \subsection lattices_def_def Definitions
 *
 * \f$t\f$- dimensional **lattices** in the real space \f$\mathbb{R}^t\f$ are
 * discrete subspaces of the real vector space \f$\mathbb{R}^t\f$ that can be
 * expressed as
 * \f{equation}{
 *  L_t = \left\{\mathbf{v} = \sum_{j=1}^t z_j\mathbf{v}_j\mid \mbox{ each } z_j\in\mathbb{Z}\right\}
 *      = \oplus_{j=1}^t \mathbb{Z} \mathbf{v}_j,
 * \label {eq:lattice}
 * \f}
 * where \f$t\f$ is a positive integer, and
 * \f$\mathbf{v}_1,\dots,\mathbf{v}_t\f$ are linearly independent vectors in \f$\mathbb{R}^t\f$
 * which form a **basis** of the lattice.
 * The matrix \f$\mathbf{V}\f$, whose \f$i\f$th row is \f$\mathbf{v}_i\f$, is the
 * corresponding **generator matrix** of \f$L_t\f$.
 * A comprehensive treatment of such lattices can be found in \cite mCON99a. The
 * algorithms implemented in *LatticeTester* need to be exact most of the time.
 * To work around this limitation, the library only considers lattices with 
 * \f$\mathbf{v}_1,\dots,\mathbf{v}_t \in \mathbb{Z}^t\f$. Note that if the basis
 * vectors are in \f$\mathbb{Q}^t\f$ instead of \f$\mathbb{Z}^t\f$ it is possible
 * **rescale** the lattice by multiplying all the vectors it contains by an
 * integer such that the resulting lattice is in \f$\mathbb{Z}^t\f$. The details
 * of this conversion are left to the user as it is not implemented.
 *
 * The **dual lattice** of \f$L_t^*\f$ is defined as
 * \f[
 * L_t^* = \{\mathbf{h} \in \mathbb{R}^t \mid \forall \mathbf{v} \in L_t, \mathbf{h}\cdot\mathbf{v} \in \mathbb{Z} \}.
 * \f]
 * The **dual** of a given basis \f$\mathbf{v}_1,\dots,\mathbf{v}_t\f$ is the set of
 * vectors \f$\mathbf{w}_1,\dots,\mathbf{w}_t\f$ in \f$\mathbb{R}^t\f$
 * such that \f$\mathbf{v}_i\cdot\mathbf{w}_j = \delta_{ij}\f$, where \f$\delta_{ij}=1\f$
 * if \f$i=j\f$, and \f$\delta_{ij}=0\f$ otherwise.
 * It forms a basis of the dual lattice.
 * These \f$\mathbf{w}_j\f$'s are the columns of the **dual basis generator
 * matrix** \f$\mathbf{W} = \mathbf{V}^{-1}\f$,
 * the inverse of the generator matrix \f$\mathbf{V}\f$.
 *
 * *LatticeTester* stores and manipulates only lattices by storing its basis
 * and, possibly, its dual basis in integer coordinates. If a lattice has an
 * integer basis, its dual is often fractional. This is a problem that is solved
 * by storing a rescaled version of the dual: the **m-dual** \f$mL_t^*\f$. When
 * using the m-dual, m is chosen so that \f$m\mathbf{W}\f$ is an integer matrix.
 * Such a m usually is defined by the application for which lattices are used.
 * It is the responsibility of the user to find it out.
 * In this software and the documentation, we assume that the appropriate
 * rescaling has already been done and we always work directly with a lattice
 * \f$\Lambda_t \subset \mathbb{Z}^t\f$ and its m-dual
 * \f$\Lambda_t^*\subset\mathbb{Z}^t\f$.
 * The advantage of this framework is that all vector coordinates are integers
 * and easily representable exactly on the computer.
 *
 * There are a few more usefull definitions needed to understand this software.
 * The determinant of the matrix \f$\mathbf{V}\f$ is equal to the volume of the
 * fundamental parallelepiped
 * \f$\{\mathbf{v} = \lambda_1\mathbf{v}_1 + \cdots + \lambda_t\mathbf{v}_t \mid
 * 0\le \lambda_i\le 1\f$ for \f$1\le i\le t\}\f$.  It is independent of
 * the choice of basis and is called the **determinant** or **volume** of \f$L_t\f$.
 * The quantity \f$n = 1/\det(L_t) = 1/\det(\mathbf{V}) = \det(\mathbf{V}^{-1})\f$
 * is called the **density** of \f$L_t\f$ and it represents the
 * average number of points per unit of volume in the lattice.
 * When \f$L_t\f$ contains \f$\mathbb{Z}^t\f$, the density \f$n\f$ is an integer equal to the
 * cardinality of the point set \f$L_t \cap [0,1)^t\f$.
 *
 * For a given lattice \f$L_t\f$ and a subset of coordinates
 * \f$I = \{i_1,\dots,i_d\} \subseteq \{1,\dots,t\}\f$, denote by \f$L_t(I)\f$
 * the projection of \f$L_t\f$ over the \f$d\f$-dimensional subspace determined
 * by the coordinates in \f$I\f$.
 * This projection is also a lattice, whose density divides that of \f$L_t\f$.
 * There are exactly \f$\det(L_t(I))/\det(L_t)\f$ points of \f$L_t\f$ that are
 * projected onto each point of \f$L_t(I)\f$.
 * In group theory language, \f$L_t(I)\f$ corresponds to a coset of \f$L_t\f$.
 *
 * A **shifted lattice** is a lattice \f$L_t\f$ shifted by a constant vector
 * \f$\mathbf{v}_0\not\in L_t\f$, i.e., a point set of the form 
 * \f$L'_t = \{\mathbf{v}+\mathbf{v}_0 : \mathbf{v} \in L_t\}\f$, where 
 * \f$L_t\f$ is a lattice.  The uniformity of a shifted lattices \f$L'_t\f$ can
 * be analyzed by subtracting the shift and analyzing the (unshifted) lattice 
 * \f$L_t\f$.
 *
 * \if LATMRG_DOC
 * \else
 * \subsection lattices_def_algo Algorithms on lattices
 * 
 * There are a few algorithms specifically doing lattice manipulations
 * implemented in *LatticeTester*. The first is the computation of a diagonal
 * basis for a lattice. Given a lattice basis \f$\mathbf{V}\f$, there always exist a
 * unimodular matrix \f$T\f$ such that
 * \f{equation}{
 *   T\mathbf{V} =
 *   \begin{bmatrix}
 *     \hat{v}_{11} & \hat{v}_{12} & \cdots & \hat{v}_{1t} \\
 *     0 & \hat{v}_{22} & \cdots & \hat{v}_{2t} \\
 *     \vdots & \ddots & \ddots & \vdots \\
 *     0 & \cdots & 0 & \hat{v}_{tt}
 *   \end{bmatrix}.
 * \f}
 * Since \f$T\f$ is unimodular, \f$T\mathbf{V}\f$ is still a basis for the
 * lattice \f$\Lambda_t\f$ and can be used in place of \f$\mathbf{V}\f$ to
 * perform computations. Lets note the lines of \f$\mathbf{V}\f$ as `V[i]` and
 * define the following algorithm:
 * \code{.py}
 * def Euclid(vector1, vector2, i):
 *   while vector2[i] != 0:
 *     int a  = vector1[i]/vector2[i] # integer division
 *     vector1 = vector1 - a * vector2
 *     vect tmp = vector2
 *     vector2 = vector1
 *     vector1 = tmp
 * \endcode
 * Then the next algorithm transforms V in a diagonal basis for lattice \f$\Lambda_t\f$:
 * \code{.py}
 * def Diagonalize(V, t):
 *   for 1 <= i <= t:
 *     for i < j <= t:
 *       Euclid(V[i], V[j], i)
 * \endcode
 *
 * Having the preceding algorithm is usefull to compute the m-dual of a lattice.
 * When m is known, it is easy to extrapolate the m-dual from a diagonal basis
 * because the matrix \f$m\mathbf{W}\f$ such that
 * \f$\mathbf{V}(m\mathbf{W})^t = m\mathbf{I}\f$ is a basis to the m-dual. As
 * pointed out in \cite rCOU96a, when we know that m is right, every of the
 * divisions in the following algorithm will be integer and the m-dual is easily
 * choosen:
 * \code{.py}
 * def BuildDual(V, W, m):
 *   W = 0
 *   Diagonalize(V, V.size())
 *   for 1 <= i <= t:
 *     W[i][i] = m / V[i][i]
 *   for 1 <= i <= t:
 *     for i > j >= 1:
 *       for j+1 <= k <= i:
 *         W[i][j] -= m * V[j][k] * W[i][k] / V[j][j]
 * \endcode
 * \endif
 *
 * \section sec_merit Measures of Uniformity
 *
 * \subsection sec_merit_short Shortest Nonzero Lattice Vector and Spectral Test
 *
 * The euclidian length \f$l\f$ of the shortest non-zero vector in the lattice
 * \f$\Lambda_t\f$ corresponds to the distance between the nearest lattice
 * points. For a given lattice density, having a shorter \f$l\f$ means that the
 * points in the lattice are more tightly packed together on fewer parallel
 * hyperplans, which is undesirable. As counter-intuitive as it seems, it turns
 * out that the uniformity of the points of the lattice is maximized when the
 * length of the shortest vector is maximized.
 * This motivates taking this \f$\ell\f$ as a measure of uniformity,
 * which we want to maximize.
 *
 * To make a measure of uniformity, we need to rescale the value of \f$\ell\f$
 * so that it can be compared between different lattices with different densities.
 * To do this, we need to make a parallel between lattices and sphere packings.
 * It is possible to see a lattice as a packing of non-interlapping spheres of
 * radius \f$\ell/2\f$ centered on every lattice point. \cite mCON99a
 * provides the theoretical foundation needed to study this packing. It turns
 * out that the proportion of space covered by these spheres is a good indicator
 * of the uniformity of the points: a more even point distribution and a longer
 * \f$\ell\f$ mean that points are at a more even distance, which is
 * preferable if we want an even point distribution.
 *
 * Using what is available in \cite mCON99a, it is also possible to provide
 * bounds on the length \f$\ell\f$. Let \f$V_t\f$ be the volume of a sphere
 * in dimension \f$t\f$. Then the proportion of space taken by spheres of radius
 * \f$\ell/2\f$ centered on each point of the lattice is
 * \f[\Delta_t = \frac{V_t \ell n}{2^t}.\f] With this equation it is to
 * rewrite \f[\ell = 2 \left(\frac{\Delta_t}{V_t n}\right)^{1/t} \leq 2\left(\frac{\Delta_t^*}{V_t n}\right)^{1/t}.\f]
 * where \f$\Delta_t^*\f$ is a bound on \f$\Delta_t\f$. \cite mCON99a provides
 * various values for Hermit constants (\cite mCON99a, \cite mNGU10l)
 * \f$\gamma_t = 4(\Delta_t^*/V_t)^{2/t}\f$ that *LatticeTester* uses in subclasses
 * of the `Normalizer` class to give a bound on \f$\ell\f$ as
 * \f$\ell \leq \gamma_t^{1/2} \det(L_t)^{1/t}\f$.
 *
 * Using these bounds, it is possible to
 * build **figures of merit**. Figures of merit are values scaled between 0 and
 * 1 that can be used to easily compare different lattice with different \f$n\f$
 * with some criterion specified beforehand. *LatticeTester* does not, however,
 * provide figures of merit by itself so this topic is not covered more in depth
 * here.
 *
 * \subsubsection sec_merit_spectral The Spectral Test
 *
 * The work previously done with \f$\Lambda_t\f$ can also be applied on
 * the shortest non-zero vector of \f$\Lambda_t^*\f$ the m-dual of \f$\Lambda_t\f$.
 * The normalization \f$\ell(\Lambda_t^*)/\ell^*\f$, with the upper bound \f$\ell^*\f$, is
 * called the spectral test and it is a widely used computation to assess the
 * uniformity of a lattice. Geometrically, \f$1/\ell(\Lambda_t)\f$ is the distance between
 * the familly of hyperplans the furter away from each other that cover the
 * points of the lattice. A large value of \f$1/\ell(\Lambda_t^*)\f$ means large empty
 * portions of space without points, this is undesirable when building a uniform
 * lattice. The Spectral Test is a widely used figure of merit on lattices (see
 * \cite rKNU98a, \cite rLEC97c, \cite rLEC99b), especially when researching
 * random number generators.
 *
 * Finding the shortest non-zero vector is equivalent to the resolution of the
 * following quadratic integer programming problem:
 *   \f{align}{
 *      \text{Minimize } & & \Vert \mathbf{v} \Vert^2 & = \mathbf{v}^\mathbf{t} \mathbf{v} & & \\ \\
 *      \text{Subject to } & & \mathbf{v} & = \sum_{i=1}^t z_i \mathbf{v}_i \\
 *                         & & 0 & < \sum_{i=1}^t |z_i|\\
 *                         & & & z_i \in \mathbb{Z}.
 *   \f}
 * Solving this problem requires the usage of integer programming and of an
 * algorithm that will ultimately amount to enumerating all the points. There
 * exists a Branch-and-Bound (B&B) procedure that specifically targets this
 * problem first introduced in \cite rDIE75a, than improved with \cite mFIN85a
 * and presented in \cite rKNU98a. It is implemented in *LatticeTester*. Just like every B&B
 * algorithm, this algorithm can take up to exponential time in \f$t\f$. To
 * speed up its computation, *LatticeTester* also provides other reduction
 * algorithms that can be applied beforehand, so that search on the basis can be
 * applied on already short vectors with a much smaller search space.
 * 
 * We first present the 3 reduction algorithms available in *LatticeTester* before
 * exposing in detail the B&B procedure.
 *
 * \subsection sec_latred Lattice Reduction Algorithms
 *
 * \subsubsection sec_latred_dieter Pairwise reduction
 * 
 * Pairwise reduction (sometimes called Dieter reduction) is a long known
 * heuristic based on the Gram-Schmidt orthogonalization. It was first used on
 * this exact problem by Dieter in \cite rDIE75a.
 *
 * Let first recall and introduce our notation for the Gram-Schmidt orthogonalization.
 * From the basis 
 * \f$\{\mathbf{v}_1, \ldots, \mathbf{v}_t\}\f$, we can get an orthogonal basis 
 * \f$\{\hat{\mathbf{v}}_1, \ldots, \hat{\mathbf{v}}_t\}\f$ by taking
 * \f{align*}{
 *   \hat{\mathbf{v}}_1 & = \mathbf{v}_1 \\
 *   \hat{\mathbf{v}}_i & = \mathbf{v}_i - \sum_{j=1}^{i-1} \mu_{ij} \hat{\mathbf{v}}_j,\ 1< i \leq t\\
 *   \mu_{ij}  & = \frac{\mathbf{v}_i \cdot \hat{\mathbf{v}}_j}{\hat{\mathbf{v}}_j \cdot \hat{\mathbf{v}}_j},\ 1 \leq j < t,\ i > j
 * \f}
 *
 * The heuristic consists in trying to reduce the length of a
 * basis vector \f$\mathbf{v}_i\f$ by subtracting from it \f$q\f$ times another
 * basis vector \f$\mathbf{v}_j\f$, for some integer \f$q\f$ and given indices
 * \f$i\not=j\f$. We want to choose \f$q\f$ as a local minima for \f$\Vert \mathbf{v}_i - q \mathbf{v}_j\Vert\f$.
 * This means that we want
 * \f{equation}{
 *   \Vert \mathbf{v}_i - (q-1) \mathbf{v}_j \Vert^2 \geq \Vert \mathbf{v}_i - q \mathbf{v}_j \Vert^2 \leq \Vert \mathbf{v}_i - (q+1) \mathbf{v}_j\Vert^2 \\
 *   \mathbf{v}_j \cdot \mathbf{v}_j + 2(\mathbf{v}_i - q \mathbf{v}_j) \cdot \mathbf{v}_j \geq 0 \leq \mathbf{v}_j \cdot \mathbf{v}_j - 2(\mathbf{v}_i - q \mathbf{v}_j) \cdot \mathbf{v}_j \\
 *   -\mathbf{v}_j \cdot \mathbf{v}_j  \leq 2(\mathbf{v}_i - q \mathbf{v}_j) \cdot \mathbf{v}_j \leq \mathbf{v}_j \cdot \mathbf{v}_j \\
 *   -\frac{1}{2} + \frac{\mathbf{v}_i \cdot \mathbf{v}_j}{\mathbf{v}_j\cdot\mathbf{v}_j} \leq q \leq \frac{1}{2} + \frac{\mathbf{v}_i \cdot \mathbf{v}_j}{\mathbf{v}_j\cdot\mathbf{v}_j}
 * \f}
 * The last line means that \f$q = \lfloor1/2 + \frac{\mathbf{v}_i \cdot \mathbf{v}_j}{\mathbf{v}_j\cdot \mathbf{v}_j}\rfloor\f$
 * is a suitable integer solution to the problem. By taking this \f$q\f$ we also
 * get that \f$\Vert \mathbf{v}_i - q \mathbf{v}_j \Vert <= \Vert \mathbf{v}_i \Vert\f$.
 * 
 * \if LATMRG_DOC
 * \else
 * Pairwise reduction can then
 * be written as the following algorithm with `V[i]`, \f$t\f$-dimensional vectors
 * that are the rows of a matrix:
 * \code{.py}
 * def Pairwise(V, t):
 *   int i = 0
 *   int k = 0
 *   while i < t:
 *    vector old = V[k]
 *    for 0 <= j < t:
 *      if j != k:
 *        int q = (V[k] * V[j]) / (V[j] * V[j])
 *        V[k] = V[k] - q * V[j]
 *    if old == V[k]:
 *      i += 1
 *    else:
 *      i = 0
 *    k += 1
 * \endcode
 * 
 * Since the algorithm is garanteed to reduce the vector length whenever it modifies
 * a vector, it is also garanteed to stop at one point because there is minimal
 * attainable length.
 * \endif
 *
 * As noted by Dieter, pairwise reductions can also be applied conjointly on the
 * primal and dual basis. The idea is simply to make it so that every time a
 * vector is modified, the other basis is changed accordingly so that 
 * \f$\mathbf{V}\mathbf{W} = mI\f$ at all times. More details are available in
 * \cite rDIE75a.
 *
 * \subsubsection sec_latred_lll Lenstra-Lenstra-Lovasz reduction
 *
 * Lenstra, Lenstra, and Lovasz \cite mLEN82a have proposed a popular form of
 * lattice basis reduction known as **LLL reduction**. Our software implements or
 * uses (via a library implementation) a slightly modified version of
 * this algorithm presented in \cite mSCH91a.
 *
 * For \f$1/4 \leq \delta < 1\f$ (usually close to 1), we say that a basis is
 * \f$\delta\f$-LLL reduced if
 * 1.  \f$ |\mu_{ij}| \leq 1/2 \f$ for \f$1 \leq j < i \leq t\f$ ;
 * 2. \f$\delta \leq \frac{\Vert \hat{\mathbf{v}}_{i+1} + \mu_{i+1\,i} 
 *    \hat{\mathbf{v}}_i \Vert^2}{\Vert \hat{\mathbf{v}}_i\Vert^2}\f$, for \f$0 < i \leq t-1 \f$.
 *
 * As stated by Victor Shoup in the [NTL documentation](https://www.shoup.net/ntl/doc/LLL.cpp.html),
 * The conditions that the vectors respect when reduced with the LLL algorithm
 * do not have a clear geometric meaning, but a \f$\delta\f$-LLL reduced basis
 * with its vectors \f$\{\mathbf{v}_1, \ldots, \mathbf{v}_t\}\f$ ordered by length
 * satisfies the following:
 * \f[
 *   (\delta-1/4)^{i-1} \leq \Vert\mathbf{v}_i\Vert^2 \lambda_i^{-2} \leq (\delta-1/4)^{1-t},\ 1 \leq i \leq t
 * \f]
 * with \f$\lambda_i\f$ the \f$i\f$-th shortest non-zero vector in the lattice.
 * This condition gives a relatively tight bound on the shortest vector in
 * the basis after the \f$\delta\f$-LLL reduction. This vector is often much shorter
 * than the one obtained with pairwise reduction and yields a faster B&B. It is
 * also notable that, in large dimensions for which the B&B is impractical, this
 * short vector can be used as an approximation of the shortest non-zero vector
 * in the lattice.
 *
 * \if LATMRG_DOC
 * \else
 * Schnorr and Euchner give the following algorithm for \f$\delta\f$-LLL reduction
 * that is used in *LatticeTester* on a lattice basis in matrix `V`, 1/2 < `delta` < 1
 * and `prec` the number of bits in the floating point arithmetic:
 * \code{.py}
 * def LLL(V, t, delta, prec):
 *   # Value initialization
 *   int k = 1
 *   bool Fc = false
 *   float matrix V' = V
 *   float vector c # Vector of dimension t
 *   float s
 *   float matrix mu # Gram-Schmidt coefficients
 *   while k < t:
 *     c[k] = V'[k]*V'[k]
 *     if k == 1:
 *       c[0] = V'[0]*V'[0]
 *     for 0 <= j < k-1:
 *       if |V'[k]*V'[j]| < 2^(-prec/2) * sqrt((V'[k]*V'[k])*(V'[j]*V'[j])):
 *         s = float(V[k]*V[j])
 *       else:
 *         s = V'[k]*V'[j]
 *       mu[k,j] = s
 *       for 0 <= i < j-1:
 *         mu[k,j] -= mu[j,i]*mu[ki]*c[i]
 *       mu[k,j] /= c[j]
 *       c[k] = c[k] - mu[k,j] * mu[k,j] * c[j]
 *     for k-1 > j > 1:
 *       int mu = mu[k,j]
 *       if |mu[k,j]| > 0.5:
 *         if |mu| > 2^(prec/2):
 *           Fc = true
 *         for 0 <= i < j-1:
 *           mu[k,i] = mu[k,i] - mu * mu[j,i]
 *         mu[k,j] = m8[k,j] - mu
 *         V[k] = V[k] - mu * b[j]
 *         V'[k] = float(V[k])
 *      if Fc:
 *        Fc = false
 *        k = max(k-1,1)
 *        break
 *      if delta * c[k-1] > c[k] + mu[k,k-1] * mu[k,k-1]c[k-1]:
 *        temp = V[k]
 *        V[k] = V[k-1]
 *        V[k-1] = temp
 *        temp = V'[k]
 *        V'[k] = V'[k-1]
 *        V'[k-1] = temp
 *        k = max(k-1, 1)
 *      else:
 *        k = k+1
 * \endcode
 * 
 * This algorithm performs in polynomial time and usually does not suffer from
 * precision problems that may arise from the usage of floating point numbers.
 * \endif
 *
 * \subsubsection sec_latred_bkz Block Korkine-Zolotarev Reduction
 *
 * The final reduction algorithm available in *LatticeTester* is the Block
 * Korkine-Zolotarev (BKZ) reduction. The objective of this reduction algorithm
 * is to provide a generalization of the previous LLL algorithm that gives
 * stronger bounds on the results. As it is, the LLL algorithm only considers
 * a condition on basis vectors two at a time. BKZ however generalizes LLL by
 * changing the condition 2 to:
 * \f[
 *   \delta \Vert \hat{\mathbf{v}}_i \Vert^2 \leq \lambda_1(L^i(\mathbf{v}_1, \ldots, \mathbf{v}_{\min(i+\beta-1, t)}))^2,\ 1 \leq i \leq t-1.
 * \f]
 * where \f$2 \leq \beta < t\f$ is called a block size, \f$\lambda_1(L)\f$ is the
 * shortest vector in lattice \f$L\f$ and \f$L_i(b_1, \ldots, b_n)\f$ is the
 * projection of \f$\{b_1,\ldots, b_n\}\f$ on
 * \f$\{\mathbf{v}_1, \ldots, \mathbf{v}_{i-1}\}\f$, which is a lattice of
 * rank \f$t-i+1\f$. A lattice respecting this condition and the condition 1 of
 * \f$\delta\f$-LLL reduction is called \f$\delta\f$-BKZ with block size \f$\beta\f$.
 *
 * BKZ reduction has been introduced in \cite mSCH87a and perfected to use a
 * variable precision in \cite mSCH91a. It turns out that BKZ reduction gives
 * tighter bounds on the shortest obtained vector in the reduced basis: provided
 * that \f$\beta-1\f$ divides \f$t-1\f$ theorem
 * 2.3 in \cite mSCH87a gives
 * \f[
 *   \lambda_1(L_t)^2 \leq \Vert \mathbf{v}_1 \Vert^2 \leq \alpha_\beta^{(t-1)/(\beta-1)} \lambda_1(L_t)^2
 * \f]
 * as a bound on the first vector in the basis. Note that \f$\alpha_\beta\f$ is
 * a constant with \f$\alpha_2 = \frac{4}{3}\f$
 * and generally \f$\alpha_\beta \leq \beta^{1+\ln\beta}\f$. This implies that
 * \f$1 < \alpha_\beta^{1/(\beta-1)} \rightarrow 1\f$ as \f$\beta\f$ increases.
 * This is better than what can be achieved with LLL, which is
 * \f[
 *   \lambda_1(L_t)^2 \leq \Vert \mathbf{v}_1 \Vert^2 \leq \frac{4}{3}^{t-1} \lambda_1(L_t)^2.
 * \f]
 * Note that, in reality, these bounds differ a little from this theory since
 * the implemented algorithms use the floating point versions \f$\delta\f$-LLL
 * and \f$\delta\f$-BKZ for efficiency.
 *
 * *LatticeTester* does not provide an implementation for the BKZ reduction
 * algorithm and relies on the NTL library to perform it. We therefore do not
 * provide pseudo-code of this algorithm.
 * 
 * \subsubsection sec_latred_precision A Quick Note on Precision
 *
 * The previous sections could have been confusing because there are many
 * variants to the presented algorithms. This is because the two
 * algorithms cannot generally be performed in polynomial time, but weakening
 * their conditions with the \f$\delta\f$ factor gives way better bounds on
 * execution times. *LatticeTester* implements and uses these weakened versions.
 * Some theory that does not concern those versions is presented for comparison
 * purposes only.
 *
 * \subsection sec_svp Shortest Vector Computation
 *
 * We now address the problem of computing a shortest nonzero vector with length \f$\ell\f$
 * in the lattice \f$\Lambda_t\f$. This problem amounts to finding integers \f$z_1,\dots,z_t\f$,
 * not all zero, such that the vector \f$\mathbf{v} = z_1 \mathbf{v}_1 + \cdots + z_t \mathbf{v}_t\f$
 * is as short as possible.  Trying all combinations for those \f$z_j\f$'s is definitely
 * not an efficient option.
 * For the Euclidean norm, we formulate this problem as a quadratic integer programming
 * (optimization) problem with decision variables \f$z_1,\dots, z_t\f$,
 * and show how to solve it by a branch-and-bound (BB) procedure.
 * Following the ideas of \cite rDIE75a \cite mFIN85a, we get the formulation
 * we eluded to before:
 *   \f{align}{
 *      \text{Minimize } & & \Vert \mathbf{v} \Vert^2 & = \mathbf{v}^\mathbf{t} \mathbf{v} & & \\ \\
 *      \text{Subject to } & & \mathbf{v} & = \sum_{i=1}^t z_i \mathbf{v}_i \\
 *                         & & 0 & < \sum_{i=1}^t |z_i|\\
 *                         & & & z_i \in \mathbb{Z}.
 *   \f}
 *
 * Suppose that the basis vectors \f$\mathbf{v}_1,\dots,\mathbf{v}_t\f$ are ordered by increasing length
 * and that our best solution so far is the vector \f$\mathbf{v}_1\f$, with square length
 * \f$\hat{\ell} = \mathbf{v}'_1 \mathbf{v}_1\f$.
 * This \f$\hat{\ell}\f$ is an upper bound on the length \f$\ell\f$ of a shortest vector.
 *
 * In the B&B algorithm, we fix successively \f$z_t\f$,
 * then \f$z_{t-1}\f$, then \f$z_{t-2}\f$, down to fixing \f$z_1\f$. Without 
 * any more constraints, this yields an (possibly infinite) exponentially growing tree. 
 * To avoid this, at each step, for any fixed values of \f$z_t,\dots,z_{j+1}\f$,
 * we compute a finite range (interval) of values of
 * \f$z_j\f$ such that all values outside that range cannot lead to a better
 * solution than \f$\hat{\ell}\f$. All These values will be tested to verify
 * that there is no possible shorter vector than the one we currently know.
 * When a shorter vector is found, \f$\mathbf{v}_1\f$ is changed to that new
 * vector and the search continues. The search ends when all combinations of
 * \f$z_j\f$ inside the intervals have been tested.
 *
 * Computing an interval for \f$z_j\f$ is the main challenge of this problem.
 * We present the approach of \cite mAFF85a to get this interval. This is what
 * is implemented in *LatticeTester*.
 *
 * At the beginning of the B&B procedure,
 * as in \cite rAFF85a \cite mFIN85a \cite rGRO88a \cite mPOH81a,
 * we compute a Cholesky decomposition \cite mGOL89a of the matrix of scalar
 * products of basis vectors \f$\mathbf{V}\mathbf{V}^t\f$ which always is
 * positive-definite:
 * \f[
 *   \mathbf{V} \mathbf{V}^t = \mathbf{U}^t \mathbf{U}
 * \f]
 * where \f$\mathbf{U}\f$ is an upper triangular matrix:
 * \f[
 * \mathbf{U} =
 * \begin{pmatrix}
 *      u_{11}   & \ldots & u_{1t} \\\
 *
 *      \vdots & \ddots &\vdots  \\\
 *
 *      \mathbf{0}  & \ldots & u_{tt}
 * \end{pmatrix}
 * \f]
 *
 * Now, if \f$\mathbf{z} = (z_1,\dots,z_t)\f$, we have a shortest
 * vector candidate \f$\mathbf{v} = \mathbf{V}^t\mathbf{z}^t\f$. Note
 * \f$r_j = \sum_{k=j+1}^t u_{jk} z_k\f$,
 * and \f$s_j = \sum_{k=j+1}^t \left(\sum_{l=k}^t u_{kl} z_l\right)^2\f$,
 * then we have \cite rAFF85a \cite mFIN85a \cite mPOH81a :
 *
 * \f{eqnarray*}{
 *  \mathbf{v}^t\mathbf{v} &=& \mathbf{z}\mathbf{V} \mathbf{V}^t \mathbf{z}^t = \mathbf{z}\mathbf{U}^t \mathbf{U} \mathbf{z}^t =
 *    \sum_{k=1}^t \left(\sum_{l=k}^t u_{kl} z_l\right)^2 \\\\
 *   &\ge& \left( u_{jj} z_j + \sum_{l=j+1}^t u_{jl} z_l\right)^2
 *    + \sum_{k=j+1}^t \left(\sum_{l=k}^t u_{kl} z_l\right)^2 \\\\
 *   &=& (u_{jj} z_j + r_j)^2 + s_{j} \quad = \; s_{j-1}.
 * \f}
 *
 * A better solution must satisfy \f$\mathbf{v}^t\mathbf{v} < \mathbf{v}_1^t \mathbf{v}_1\f$, which implies
 * \f$(u_{jj} z_j + r_j)^2 + s_j < \mathbf{v}_1^\mathbf{t} \mathbf{v}_1\f$.
 * centering the inequalities around \f$z_j\f$ gives the following bounds
 * \f[
 *   \left\lceil {-(\mathbf{v}_1^\mathbf{t} \mathbf{v}_1-s_j)^{1/2} - r_j\over u_{jj}}\right\rceil
 *     \;\le z_j\le\;
 *   \left\lfloor {(\mathbf{v}_1^\mathbf{t} \mathbf{v}_1-s_j)^{1/2} - r_j\over u_{jj}}\right\rfloor.
 *   \tag{bounds}
 * \f]
 *
 * Note that to obtain these bounds, the knowledge of \f$z_t,\dots,z_j\f$ is
 * needed and that this strategy uses the continuous relaxation of the original
 * problem. Finding and applying those bounds is a cutting plane method.
 * The numbers obtained mean that the possible values of \f$z_j\f$ to find a
 * shorter vector in the lattice are in the interval. We can restrict ourselves
 * to the integers that lie in that interval when branching from the node
 * \f$\{z_t,\dots, z_j\}\f$.
 * Note that \f$s_t = r_t = 0\f$, so at the beginning the bounds on \f$z_t\f$ are
 * given by \f$z_t^2 \le \mathbf{v}_1^\mathbf{t} \mathbf{v}_1\f$.
 *
 * \if LATMRG_DOC
 * \else
 * The algorithm explores a B&B tree in which each node corresponds to
 * a partial solution \f$(z_t,\dots,z_{j})\f$. This node has a child
 * \f$(z_t,\dots,z_{j},z_{j-1})\f$ for each value of \f$z_j\f$ that satisfies
 * the bounds and the root has a child for each \f$z_t\f$ such that
 * \f$z_t^2 \le \mathbf{v}_1^\mathbf{t} \mathbf{v}_1\f$.
 * When no \f$z_j\f$ satisfies the bounds (when the interval is empty)
 * the corresponding node has no child and the branch is a dead end.
 * When we reach a tree leaf that represents a full admissible solution \f$(z_t,\dots,z_1)\f$,
 * we have just found a shorter vector \f$\mathbf{v}\f$ than our current shortest vector \f$\mathbf{v}_1\f$.
 * We can then update the basis in a way that it contains \f$\mathbf{v}\f$ as its new \f$\mathbf{v}_1\f$,
 * and change the other vectors in a way that they still form a basis of our lattice.
 *
 * More specifically (without repeating the computations above) the B&B algorithm
 * of *LatticeTester* is the following, using `V` a lattice generator matrix with
 * vectors ordered by length, `t` the dimension, `z` a candidate for the last `h`
 * values of \f$z\f$.
 * \code{.py}
 * def B&B(V, t, z, h):
 *   if h == t:
 *     int i = 0
 *     while z[i] == 0:
 *       i++
 *     V[i] += (z[i]-1)*V[i]
 *     for i < j < t:
 *       V[i] += z[j]*V[j]
 *     Sort(V)
 *     return true
 *   int min, max = GetBounds(V, t, z, h)
 *   if max < min:
 *     # There is no possible child
 *     return false
 *   i = min
 *   while min <= i <= max:
 *     if h = t-1
 *       # Avoid the null vector
 *       vector v = 0
 *       for 0 <= j < t:
 *         v += z[j]*V[j]
 *       if v == 0:
 *         continue
 *     if h == 0 and i < 0:
 *       # -v and v are in the lattice and have the same length
 *       continue
 *     if B&B(V, t, (i,z), h+1):
 *       # We found a shorter vector
 *       if h > 0:
 *         # Updating the whole tree, getting back to the root
 *         return true
 *       min, max = GetBounds(V, t, z, h)
 *       i = min
 *       continue
 *     i += 1
 *   return false
 * \endcode
 * To call this function, one would use the generator matrix for `V`, \f$t\f$ as
 * `t`, an empty vector as `z` and `h=0`. This assumes that GetBounds returns
 * the lower and upper bounds as above and that Sort sorts the vectors in V
 * such that `||V[i]|| < ||V[j]||` if `0 <= i < j < t`.
 * 
 * This algorithm stops when every node in the tree returns false. This means
 * that there is no combination of \f$z_j\f$ that yields a shorter vector for
 * the lattice than the current `V[0]` and that this `V[0]` therefore is the
 * shortest non-zero vector in the lattice.
 * Note that this can use a `static`
 * computation of the Choleski decomposition that is only updated when `V`
 * changes or when the function is called for the first time. This would reduce
 * the computing time dramatically. Although this does not change the exactitude
 * of the algorithm, surveying \f$z\f$'s is a different order in the `while`
 * loop can shorten the execution time.  We use `i = (min+max)/2`
 * first, then `i = (min+max)/2±1`, `i = (min+max)/2±2`, ... which we
 * experimentally determined to be the fastest way to get to a solution leaf
 * that improves the current shortest vector (note that this is not exactly what
 * is in the pseudo-code to make it more readable).
 * Finally, since finding a new shorter vector can consequently reduce the size
 * of the tree by giving way better cuts, each time the length of the vector is
 * shortened, we go back to the root of the tree.
 *
 * The total time taken by this B&B algorithm is roughly proportional to the number of
 * tree nodes visited.
 * One major drawback is that in the worst case, this number of nodes typically
 * grows exponentially with the dimension.
 * It is therefore important to reduce this number as much possible.
 * It helps to start with a basis in which \f$\mathbf{v}_1\f$ is shorter.
 * This shortens the search interval determined by the bounds at each level \f$j\f$,
 * and can greatly reduce the number of nodes that must be examined.
 * The lattice reduction algorithms presented above (\ref sec_latred) are part
 * of *LatticeTester* to overcome this difficulty.
 * For the same reason, it also helps it we quickly find a tree leaf that corresponds to
 * an improved solution, because it can reduce the size of the tree.
 * \endif
 *
 * Observe that if \f$\mathbf{v} = \mathbf{z}\mathbf{V}\f$ is a lattice vector,
 * \f$-\mathbf{v} = (-\mathbf{z})\mathbf{V}\f$ is also a lattice
 * vector with the same norm.  We can exploit this symmetry to cut the BB tree in half,
 * simply by considering only non-negative values of \f$z_t\f$.
 * We can do that because any vector \f$\mathbf{z}\f$ with \f$z_t < 0\f$ has an equivalent vector
 * \f$-\mathbf{z}\f$ having \f$z_t > 0\f$.
 * */
