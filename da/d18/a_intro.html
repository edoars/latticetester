<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Lattice Tester Manual: Background</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../navtreedata.js"></script>
<script type="text/javascript" src="../../navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js", "TeX/AMSmath.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
<link href="../../latticetester.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Lattice Tester Manual
   &#160;<span id="projectnumber">0.1.0-work-43</span>
   </div>
   <div id="projectbrief">Software Package For Testing The Uniformity Of Integral Lattices In The Real Space</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "../../search",false,'Search');
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('../../',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('da/d18/a_intro.html','../../');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Background </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><em><a class="el" href="../../d8/d74/namespaceLatticeTester.html" title="Lattice namespace. ">LatticeTester</a></em> is a software library and tool to measure theoretical measures of uniformity (or figures of merit) for lattices in the \(t\)-dimensional the real space \(\mathbb{R}^t\) that contain \(\mathbb{Z}^t\) as a sublattice or are contained in \(\mathbb{Z}^t\).</p>
<p>Such lattices are encountered for example in quasi-Monte Carlo integration (by lattice rules) and in the analysis of uniform random number generators defined by linear recurrences modulo a large integer. Measures of uniformity include the length of the shortest nonzero vector in the lattice or in its dual (the spectral test), the Beyer ratio, \(\mathcal{P}_\alpha\), as well as figures of merit that take normalized versions of these measures over projections of the lattice on subsets of the \(t\) coordinates, and then take a weighted sum or the worst-case over the class of considered projections. <em><a class="el" href="../../d8/d74/namespaceLatticeTester.html" title="Lattice namespace. ">LatticeTester</a></em> is used in particular in the <em>LatNet Builder</em> and <em>LatMRG</em> software tools, designed to construct and analyze lattice rules and linear generators.</p>
<p>The purpose of <em><a class="el" href="../../d8/d74/namespaceLatticeTester.html" title="Lattice namespace. ">LatticeTester</a></em> is to compute various figures of merit that serve as measures of uniformity for lattices in the \(t\)-dimensional real space \(\mathbb{R}^t\) that contain \(\mathbb{Z}^t\) as a sublattice or are contained in \(\mathbb{Z}^t\) <a class="el" href="../../d0/de3/citelist.html#CITEREF_vLEC00b">[14]</a> <a class="el" href="../../d0/de3/citelist.html#CITEREF_mSLO94a">[28]</a> .</p>
<p>The lattices we consider are discrete vector spaces in \(\mathbb{R}^t\) and one is often interested in the (finite) intersection of the lattice with the \(t\)-dimensional unit hypercube \([0,1)^t\). This is the case for <em>Lattice rules</em>, which are multivariate integration methods that take the average value of a function at this set of points (sometimes randomly shifted modulo 1) to estimate the integral of the function over the unit cube <a class="el" href="../../d0/de3/citelist.html#CITEREF_vLEC00b">[14]</a> <a class="el" href="../../d0/de3/citelist.html#CITEREF_vLEC09f">[19]</a> <a class="el" href="../../d0/de3/citelist.html#CITEREF_mSLO94a">[28]</a>. Bounds on the (mean square) integration error can be obtained in terms of figures of merit computed by the present software.</p>
<p>This same set of points is also the set of all vectors of \(t\) successive values produced by certain types of linear congruential generators in scalar or matrix form. In that context, we want the point set to cover the unit hypercube as uniformly as possible, and a standard way of measuring this uniformity is the spectral test <a class="el" href="../../d0/de3/citelist.html#CITEREF_rCOV67a">[3]</a> <a class="el" href="../../d0/de3/citelist.html#CITEREF_rKNU98a">[12]</a> <a class="el" href="../../d0/de3/citelist.html#CITEREF_rLEC97c">[13]</a>, that computes the length of the shortest nonzero vector in the dual lattice. The inverse of this length represents the maximal distance between successive hyperplanes in a family of equidistant hyperplanes that contain all the lattice points. We want this maximal distance to be not too large for the points to cover the space evenly. <em><a class="el" href="../../d8/d74/namespaceLatticeTester.html" title="Lattice namespace. ">LatticeTester</a></em> permits one to compute this distance for the lattice and for any of its projections over a subset of coordinates.</p>
<p>In these applications, the lattice of interest contains \(\mathbb{Z}^t\) and its dual lattice is contained in \(\mathbb{Z}_t\). An important difference between these two applications (from the practical viewpoint) is that the number of lattice points per unit of volume, i.e., the number \(n\) of lattice points in the unit hypercube \([0,1)^t\), is usually modest (at most in the thousands or millions) for lattice rules, and much larger (say, from \(2^{100}\) to \(2^{1000}\) or more) in the case of random number generators (because the period of the generator typically cannot exceed \(n\)). For this reason, the figures of merit for these two applications are typically not the same. The most relevant measures for lattice rules (e.g., \(\mathcal{P}_\alpha\) with weights) require a computing time that increases at least linearly (or faster) with \(n\) and are unusable when \(n \ge 2^{100}\). The spectral test, whose computing time is exponential in \(t\) but only logarithmic in \(n\), appears more appropriate in this situation.</p>
<p>For more details on lattices, see for example <a class="el" href="../../d0/de3/citelist.html#CITEREF_mCON99a">[2]</a> <a class="el" href="../../d0/de3/citelist.html#CITEREF_mSLO94a">[28]</a>. Here we use \(t\) for the lattice dimension, as do many papers and books on linear congruential generators (e.g., <a class="el" href="../../d0/de3/citelist.html#CITEREF_rKNU98a">[12]</a> <a class="el" href="../../d0/de3/citelist.html#CITEREF_rLEC90a">[15]</a> <a class="el" href="../../d0/de3/citelist.html#CITEREF_rLEC96b">[16]</a>). Most papers on lattice rules use \(s\) or \(d\) instead.</p>
<p>The rest of this document is organized as follows. In the next section, we define the lattices considered here and recall their main properties. In section <a class="el" href="../../da/d18/a_intro.html#sec_merit">Measures of Uniformity</a>, we define and discuss the various figures of merit that the software can compute.</p>
<h1><a class="anchor" id="lattices"></a>
Lattices in the Real Space</h1>
<h2><a class="anchor" id="lattices_def"></a>
Definition of a Lattice</h2>
<p>We start with <em>lattices</em> over \(\mathbb{Z}\) (or \(\mathbb{Z}\)-lattices) in the real space \(\mathbb{R}^t\), which are discrete subspaces of the real vector space \(\mathbb{R}^t\) that can be expressed as </p><p class="formulaDsp">
\[ L_t = \left\{\mathbf{v} = \sum_{j=1}^t z_j\mathbf{v}_j\mid \mbox{ each } z_j\in\mathbb{Z}\right\} = \oplus_{j=1}^t \mathbb{Z} \mathbf{v}_j, \label {eq:lattice} \]
</p>
<p> where \(t\) is a positive integer, and \(\mathbf{v}_1,\dots,\mathbf{v}_t\) are linearly independent vectors in \(\mathbb{R}^t\) which form a <b>basis</b> of the lattice. The matrix \(\mathbf{V}\), whose \(i\)th row is \(\mathbf{v}_i\), is the corresponding <b>generator matrix</b> of \(L_t\). A comprehensive treatment of such lattices can be found in <a class="el" href="../../d0/de3/citelist.html#CITEREF_mCON99a">[2]</a> .</p>
<p>The determinant of the matrix \(\mathbf{V}\) is equal to the volume of the fundamental parallelepiped \(\{\mathbf{v} = \lambda_1\mathbf{v}_1 + \cdots + \lambda_t\mathbf{v}_t \mid 0\le \lambda_i\le 1\) for \(1\le i\le t\}\). It is independent of the choice of basis. It is called the <b>determinant</b> of \(L_t\). The quantity \(n = 1/\det(L_t) = 1/\det(\mathbf{v}) = \det(\mathbf{v}^{-1})\) is called the <b>density</b> of \(L_t\) and it represents the average number of points per unit of volume. When \(L_t\) contains \(\mathbb{Z}^t\), the density \(n\) is an integer equal to the cardinality of the point set \(L_t \cap [0,1)^t\).</p>
<p>For a given lattice \(L_t\) and a subset of coordinates \(I = \{i_1,\dots,i_d\} \subseteq \{1,\dots,t\}\), denote by \(L_t(I)\) the projection of \(L_t\) over the \(d\)-dimensional subspace determined by the coordinates in \(I\). This projection is also a lattice, whose density divides that of \(L_t\). There are exactly \(\det(L_t(I))/\det(L_t)\) points of \(L_t\) that are projected onto each point of \(L_t(I)\). In group theory language, \(L_t(I)\) corresponds to a coset of \(L_t\).</p>
<p>A <b>shifted lattice</b> is a lattice \(L_t\) shifted by a constant vector \(\mathbf{v}_0\not\in L_t\), i.e., a point set of the form \(L&#39;_t = \{\mathbf{v}+\mathbf{v}_0 : \mathbf{v} \in L_t\}\), where \(L_t\) is a lattice. The uniformity of a shifted lattices \(L&#39;_t\) can be analyzed by subtracting the shift and analyzing the (unshifted) lattice \(L_t\).</p>
<p>For a positive integer \(m\), The <b>dual lattice</b> of \(L_t\) is defined as </p><p class="formulaDsp">
\[ L_t^* = \{\mathbf{h} \in \mathbb{R}^t \mid \forall \mathbf{v} \in L_t, \mathbf{h}\cdot\mathbf{v} \in \mathbb{Z} \}. \]
</p>
<p> The <b>dual</b> of a given basis \(\mathbf{v}_1,\dots,\mathbf{v}_t\) is the set of vectors \(\mathbf{w}_1,\dots,\mathbf{w}_t\) in \(\mathbb{R}^t\) such that \(\mathbf{v}_i\cdot\mathbf{w}_j = \delta_{ij}\), where \(\delta_{ij}=1\) if \(i=j\), and \(\delta_{ij}=0\) otherwise. It forms a basis of the dual lattice. These \(\mathbf{w}_j\)'s are the columns of the matrix \(\mathbf{v}^{-1}\), the inverse of the matrix \(\mathbf{v}\).</p>
<h2><a class="anchor" id="lattices_rescaling"></a>
Rescaling to lattices in the integer space</h2>
<p>For the applications targeted by this software, the lattice \(L_t\) either contains, or is contained in, the integer lattice \(\mathbb{Z}^t\); i.e., \(\mathbb{Z}^t\subseteq L_t\) or \(L_t\subseteq \mathbb{Z}^t\). When \(L_t\) satisfies the first condition, then its dual satisfies the second, and vice-versa. When \(\mathbb{Z}^t\subseteq L_t\), there is always an integer \(m \ge 1\) such that all the coordinates of all vectors are multiple of \(1/m\), and one can rescale \(L_t\) by a factor of \(m\) to obtain the \(\mathbf{m}\) <b>-scaled</b> lattice \(\Lambda_t = m L_t\) whose vectors have only integer coordinates, i.e., \(\Lambda_t \subseteq \mathbb{Z}^t\) is a \(\mathbb{Z}\)-lattice in \(\mathbb{Z}^t\). The rows of \(m \mathbf{V}\) form a basis of \(\Lambda_t\), also called an \(\mathbf{m}\) <b>-scaled basis</b> for \(L_t\), and the columns of \(\mathbf{W}\) are its \(\mathbf{m}\) <b>-dual basis</b>. They are a basis of \(\Lambda^*_t = L^*_t\), the \(\mathbf{m}\) <b>-dual lattice</b> of \(\Lambda_t\). When \(L_t\subset \mathbb{Z}^t\), there is an integer \(m \ge 1\) such that \(m L^*_t \subseteq \mathbb{Z}^t\), in which case we can define \(\Lambda^*_t = m L^*_t\) and \(\Lambda_t = L_t\).</p>
<p>More generally, if there are positive integers \(m_1\) and \(m_2\) such that \(\Lambda_t = m_1 L_t \subseteq \mathbb{Z}^t\) and \(\Lambda_t^* = m_2 L_t^* \subseteq \mathbb{Z}^t\), then we can work with \(\Lambda_t\) and its \(m\)-dual lattice \(\Lambda_t^*\), where \(m = m_1 m_2\). That is, we rescale both the lattice and its dual. Note that scaling a lattice by \(m\) multiplies all vector lengths by \(m\) and all volumes by \(m^t\), and it divides the lattice density by \(m^t\).</p>
<dl class="section remark"><dt>Remarks</dt><dd><b>Pierre</b>: Oups, ici je vois que la densite devient un nombre reel tres petit... Pas 100% certain que c'est une bonne idee de travailler avec \(\Lambda_t\) et oublier le scaling, car cela change la normalisation... Mais cela rend quand meme les choses plus generales.</dd></dl>
<p>In this software and in the remainder of this document, we assume that the appropriate rescaling has already been done and we always work directly with the rescaled versions \(\Lambda_t\) and \(\Lambda_t^*\), which are \(\mathbb{Z}\)-lattices over \(\mathbb{Z}^t\) and are \(m\)-dual to each other. The advantage is that in this framework, all vector coordinates are integers and this permit us to always and easily represent them exactly on the computer. With a slight abuse of notation, we will use \(\mathbf{V}\) with columns \(\mathbf{V}_1,\dots,\mathbf{V}_t\) to represent a basis of \(\Lambda_t\) and \(\mathbf{W}\) with rows \(\mathbf{W}_1,\dots,\mathbf{W}_t\) for a basis of \(\Lambda_t^*\).</p>
<p>A \(\mathbb{Z}\)-lattice \(\Lambda_t\) can be uniquely specified by selecting a basis \(\mathbf{V}\) of \(t\) linearly independent vectors in \(\mathbb{Z}^t\). The \(m\)-dual basis \(\mathbf{W}\) can then be computed for any integer \(m\ge 2\). However, the entries of \(\mathbf{W}\) are not necessarily all integers for any \(m\); this holds only under certain conditions on \(\mathbf{V}\) and \(m\). In the applications targeted by this software, the basis and its \(m\) dual are typically constructed together in a way that these conditions are guaranteed to be satisfied. Our software can take advantage of this.</p>
<dl class="section remark"><dt>Remarks</dt><dd><b>Pierre</b>: Must define <em>rescaled integration lattice of rank 1</em> earlier.</dd></dl>
<p>In the case of a rescaled integration lattice of rank 1, it suffices to specify the generating vector \(\mathbf{a} = \mathbf{V}_1\) and an integer \(m &gt; 0\) such that the vectors \(\mathbf{V}_2= m \mathbf{e}_2, \dots, \mathbf{V}_t = m \mathbf{e}_t\) complete a basis, where the \(\mathbf{e}_j\) are the unit vectors.</p>
<p>For all lattices, we want to be able to easily enumerate the lattice points that lie in the scaled unit hypercube \([0,m)^t\) for an appropriate scaling factor \(m\); i.e., the points of \(\Lambda_t \cap [0,m)^t\), and perhaps their rescaled versions to \([0,1)^t\). For a rescaled integration lattice of rank 1, this is easy: These are the points of the form \(\mathbf{V} = i \mathbf{V}_1 \bmod 1\) for \(i=0,1,2, \dots\).</p>
<dl class="section remark"><dt>Remarks</dt><dd><b>Pierre</b>:It would be good to have a way to enumerate the points of \(L_t \cap [0,1)^t\) for a more general lattice.</dd></dl>
<h1><a class="anchor" id="sec_merit"></a>
Measures of Uniformity</h1>
<dl class="section remark"><dt>Remarks</dt><dd><b>Pierre</b>: See Section 3.2.8 of my class notes for more details on the uniformity measures, how to compute them, and how to normalize them to values between 0 and 1.</dd></dl>
<h2><a class="anchor" id="spectral"></a>
Shortest Nonzero Lattice Vector</h2>
<p>The Euclidean length \(\mathit{l}\) of the shortest nonzero lattice vector in the lattice \(\Lambda_t\), say with Euclidean norm, corresponds to the distance between the nearest lattice points. All integer multiples of this shortest vector are regularly-spaced points at distance \(\mathit{l}\) of each other on a straight line that passes through the origin, and the entire lattice is covered by shifted replicates of this straight line. A shorter distance between successive points on the line means more points per unit of length on the line, which means that all lattice points are covered by fewer lines per unit of volume, that are farther away from each other. This is undesirable.</p>
<dl class="todo"><dt><b><a class="el" href="../../dd/da0/todo.html#_todo000003">Todo:</a></b></dt><dd><b>Pierre</b>: Add an example of this, with a figure.</dd></dl>
<p>That is, for a given lattice density \(\eta\), for good uniformity, we want the shortest nonzero vector to be long. This motivates taking this \(\mathit{l}\) as a measure of uniformity, which we want to maximize.</p>
<dl class="section remark"><dt>Remarks</dt><dd><b>Pierre</b>: Attention: Dans \(\Lambda_t\), avec un scaling par le facteur \(m\), la densit\'e a \'et\'e r\'eduite par le facteur \(m^t\). Elle d\'epend maintenant de \(t\) et est souvent tr`es proche de 0.</dd></dl>
<p>We can view the lattice as a way of packing the space by non-overlapping spheres of radius \(\mathit{l}/2\), with one sphere centered at each lattice point. We have \(\eta\) spheres per unit of volume. If we rescale by the factor \(2/\mathit{l}\) so that the radius of each sphere is 1, we obtain \(\delta_t = (\mathit{l}/2)^t \eta\) unit spheres per unit volume. This number \(\delta_t\) is called the {<em>center</em> density\/} of the lattice. For a general \(t\)-dimensional lattice, it has the upper bound \(\delta_t^* = (\gamma_t /4)^{t/2}\), where \(\gamma_t\) is the <em>Hermite constant</em> for dimension \(t\) <a class="el" href="../../d0/de3/citelist.html#CITEREF_mCON99a">[2]</a> <a class="el" href="../../d0/de3/citelist.html#CITEREF_mGRU87a">[9]</a>. This gives the following upper bound \(\mathit{l}^*(\eta)\) on \(\mathit{l}\) for a lattice of density \(\eta\): </p><p class="formulaDsp">
\[ \mathit{l} \le \mathit{l}^*(\eta) \stackrel{def}{=} 2(\delta_t^*/\eta)^{1/t} = \gamma_t^{1/2} \eta^{-1/t}. \]
</p>
<p> Note that some authors use \(\gamma_t\) to denote our \(\gamma_t^{1/2}\). The Hermite constants \(\gamma_t\) are known exactly only for \(t\le 8\). In those dimensions, the densest lattice packings are attained by the <em>laminated</em> lattices <a class="el" href="../../d0/de3/citelist.html#CITEREF_mCON99a">[2]</a> .</p>
<p>Knowing the Hermite constants, or good bounds or approximations of them for \(t &gt; 8\), is useful because it allows us to normalize \(\mathit{l}\) to a value between 0 and 1 by taking \(\mathit{l}/\mathit{l}^*(\eta)\). This is convenient for comparing uniformity measures for different values of \(t\) and \(\eta\), and we will use that to define figures of merit that take several projections into account. Good values of this measure are close to 1 and bad values are close to 0.</p>
<p>Conway and Sloane <a class="el" href="../../d0/de3/citelist.html#CITEREF_mCON99a">[2]</a> [Table 1.2] give the values of \(\delta_t^*\) for \(t\le 8\), and provide lower and upper bounds on \(\delta_t^*\) for other values of \(t\). The largest value of \(\mathit{l}^2/n^{2/t}\) obtained so far for concrete lattice constructions is a lower bound on \(\gamma_t\), which we denote by \(\gamma_t^{\mathrm{B}}\). Such values are given in Table 1.2 of <a class="el" href="../../d0/de3/citelist.html#CITEREF_mCON99a">[2]</a>, page 15, in terms of \(\delta^*\). The laminated lattices, which give the lower bound \(\mathit{l}^2/n^{2/t} \ge \gamma_t^{\rm L} = 4 \lambda_t^{-1/t}\), where the constants \(\lambda_t\) are given in <a class="el" href="../../d0/de3/citelist.html#CITEREF_mCON99a">[2]</a> [Table 6.1, page 158] for \(t\le 48\), <b>Pierre</b>: Check page. are the best constructions in dimensions 1 to 29, except for dimensions 10 to 13. For \(t\le 8\), one has \(\gamma_t^{\rm L} = \gamma_t\).</p>
<p>Minkowski proved that there exists lattices with density satisfying \(\delta_t \ge \zeta(t) / (2^{t-1} V_t)\) where \(\zeta(t) = \sum_{k=1}^\infty k^{-t}\) is the Riemann zeta function and \(V_t = \pi^{t/2} / (t/2)!\) is the volume of a \(t\)-dimensional sphere of radius 1. This bound provides a lower bound \(\gamma_t^{\rm Z}\) on \(\gamma_t\).</p>
<p>An upper bound on \(\gamma_t\) is obtained via the bound of Rogers on the density of sphere packings <a class="el" href="../../d0/de3/citelist.html#CITEREF_mCON99a">[2]</a> . This upper bound can be written as \( \gamma_t^{\rm R} = 4* 2^{2R(t)/t} \) where \(R(t)\) can be found in Table~1.2 of <a class="el" href="../../d0/de3/citelist.html#CITEREF_mCON99a">[2]</a> for \(t\le 24\), and can be approximated with \(O(1/t)\) error and approximately 4 decimal digits of precision, for \(t\ge 25\), by </p><p class="formulaDsp">
\[ R(t) = \frac{t}{2} \,\log_2\left(\frac{t}{4\pi e}\right) + \frac{3}{2} \log_2 (t) - \log_2 \left(\frac{e}{\sqrt{\pi}}\right) + \frac{5.25}{t + 2.5}. \]
</p>
<p> Table~1 in <a class="el" href="../../d0/de3/citelist.html#CITEREF_rLEC99c">[17]</a> gives the ratio \((\gamma_t^{\rm L} / \gamma_t^{\rm R})^{1/2}\), of the lower bound over the upper bound on \(\mathit{l}\), for \(1\le t\le 48\). This ratio tends to decrease with \(t\), but not monotonously.</p>
<p>&ndash; Notation for standardized measure.</p>
<h1><a class="anchor" id="bb"></a>
Computing a shortest vector for the Euclidean norm</h1>
<h2><a class="anchor" id="bb_IP"></a>
Integer optimization problem and branch-and-bound procedure</h2>
<p>We now address the problem of computing a shortest nonzero vector with length \(\ell_t\) in the lattice \(\Lambda_t\). This problem amounts to finding integers \(z_1,\dots,z_t\), not all zero, such that the vector \(\mathbf{v} = z_1 \mathbf{v}_1 + \cdots + z_t \mathbf{v}_t\) is as short as possible. Trying all combinations for those \(z_j\)'s is definitely not an efficient option. For the Euclidean norm, we formulate this problem as a quadratic integer programming (optimization) problem with decision variables \(z_1,\dots, z_t\), and show how to solve it by a branch-and-bound (BB) procedure, following the ideas of <a class="el" href="../../d0/de3/citelist.html#CITEREF_rDIE75a">[4]</a> <a class="el" href="../../d0/de3/citelist.html#CITEREF_mFIN85a">[5]</a>.</p>
<p>Our quadratic integer program (for the Euclidean norm) can be written as </p><p class="formulaDsp">
\begin{align} \text{Minimize } &amp; &amp; \Vert \mathbf{v}\Vert^2 &amp; = \mathbf{v}^\mathbf{t} \mathbf{v} &amp; &amp; \\\\ \text{Subject to } &amp; &amp; \mathbf{v} &amp; = \sum_{i=1}^t z_i \mathbf{v}_i, z_i \in \mathbb{Z}, &amp; &amp; \sum_{i=1}^t |z_i| &gt; 0.\\ \end{align}
</p>
<p>Suppose that the basis vectors \(\mathbf{v}_1,\dots,\mathbf{v}_t\) are ordered by increasing length and that our best solution so far is the vector \(\mathbf{v}_1\), with square length \(\ell^2 = \mathbf{v}&#39;_1 \mathbf{v}_1\). This \(\ell\) is an upper bound on the length \(\ell_t\) of a shortest vector.</p>
<p>In the BB algorithm, we fix successively \(z_t\), then \(z_{t-1}\), then \(z_{t-2}\), etc. At each step, for any fixed values of \(z_t,\dots,z_{j-1}\) that we consider, we will compute a finite range (interval) of values of \(z_j\) such that all values outside that range cannot lead to a better solution, and will scan the values of \(z_j\) in this range. This interval is obtained as follows.</p>
<p>Let us see now how the lower bound \(s_{j-1}\) on \(V&#39;V\) is obtained.</p>
<p>At the beginning of the BB procedure, as in <a class="el" href="../../d0/de3/citelist.html#CITEREF_rAFF85a">[1]</a> <a class="el" href="../../d0/de3/citelist.html#CITEREF_mFIN85a">[5]</a> <a class="el" href="../../d0/de3/citelist.html#CITEREF_rGRO88a">[8]</a> <a class="el" href="../../d0/de3/citelist.html#CITEREF_mPOH81a">[24]</a>, we compute a Cholesky decomposition <a class="el" href="../../d0/de3/citelist.html#CITEREF_mGOL89a">[7]</a> of the matrix of scalar products of basis vectors: </p><p class="formulaDsp">
\[ \mathbf{V}^\mathbf{t} \mathbf{V} = \mathbf{U}^\mathbf{t} \mathbf{U} \]
</p>
<p> where \(\mathbf{U}\) is an upper triangular matrix:</p>
<p class="formulaDsp">
\[ \mathbf{U} = \begin{pmatrix} u_{11} &amp; \ldots &amp; u_{1t} \\\ \vdots &amp; \ddots &amp;\vdots \\\ \mathbf{0} &amp; \ldots &amp; u_{tt} \end{pmatrix} \]
</p>
<p>Now, if \(\mathbf{z} = (z_1,\dots,z_t)^\mathbf{t}\), \(\mathbf{v} = \mathbf{V}\mathbf{z}\), \(r_j = \sum_{\ell=j+1}^t u_{j\ell} z_\ell\), and \(s_j = \sum_{k=j+1}^t \left(\sum_{\ell=k}^t u_{k\ell} z_l\right)^2\), then we have <a class="el" href="../../d0/de3/citelist.html#CITEREF_mPOH81a">[24]</a> <a class="el" href="../../d0/de3/citelist.html#CITEREF_mFIN85a">[5]</a> <a class="el" href="../../d0/de3/citelist.html#CITEREF_rAFF85a">[1]</a> :</p>
<p class="formulaDsp">
\begin{eqnarray*} \mathbf{v}^\mathbf{t}\mathbf{v} &amp;=&amp; z&#39;\mathbf{V}^\mathbf{t} \mathbf{V} z = z&#39;\mathbf{U}^\mathbf{t} \mathbf{U} z = \sum_{k=1}^t \left(\sum_{\ell=k}^t u_{k\ell} z_l\right)^2 \\\\ &amp;\ge&amp; \left( u_{jj} z_j + \sum_{\ell=j+1}^t u_{j\ell} z_\ell\right)^2 + \sum_{k=j+1}^t \left(\sum_{\ell=k}^t u_{k\ell} z_l\right)^2 \\\\ &amp;=&amp; (u_{jj} z_j + r_j)^2 + s_{j} \quad = \; s_{j-1}. \end{eqnarray*}
</p>
<p>A better solution must satisfy \(\mathbf{v}^\mathbf{t}\mathbf{v} &lt; \mathbf{v}_1^\mathbf{t} \mathbf{v}_1\), which implies</p>
<p>\((u_{jj} z_j + r_j)^2 + s_j &lt; \mathbf{v}_1^\mathbf{t} \mathbf{v}_1\), i.e.</p>
<p><a class="anchor" id="REF__eq_bounds"></a> </p><p class="formulaDsp">
\[ \left\lceil {-(\mathbf{v}_1^\mathbf{t} \mathbf{v}_1-s_j)^{1/2} - r_j\over u_{jj}}\right\rceil \;\le z_j\le\; \left\lfloor {(\mathbf{v}_1^\mathbf{t} \mathbf{v}_1-s_j)^{1/2} - r_j\over u_{jj}}\right\rfloor. \tag{bounds} \]
</p>
<p>What we have just done is to fix \(z_t,\dots,z_j\) and relax the integrity constraints on \(z_{j-1},\dots,z_1\). When considering the possible values of \(z_j\), we can restrict ourselves to the integers that lie in the interval specified by <a class="el" href="../../da/d18/a_intro.html#REF__eq_bounds">(bounds)</a>. Note that \(s_t = r_t = 0\), so at the beginning the bounds on \(z_t\) are given by \(z_t^2 \le \mathbf{v}_1^\mathbf{t} \mathbf{v}_1\).</p>
<p>The algorithm thus explores a BB tree in which each node corresponds to a partial solution \((z_t,\dots,z_{j-1})\). This node has a son \((z_t,\dots,z_{j-1},z_j)\) for each value of \(z_j\) that satisfies the bounds <a class="el" href="../../da/d18/a_intro.html#REF__eq_bounds">(bounds)</a>. The root has a son for each \(z_t\) such that \(z_t^2 \le \mathbf{v}_1^\mathbf{t} \mathbf{v}_1\). When no \(z_j\) satisfies the bounds <a class="el" href="../../da/d18/a_intro.html#REF__eq_bounds">(bounds)</a>, i.e., the interval is empty, the corresponding node has no son, so this branch is a dead end. When we reach a tree leaf that represents a full admissible solution \((z_t,\dots,z_1)\), we have just found a shorter vector \(\mathbf{v}\) than our current shortest vector \(\mathbf{v}_1\). We can then update the basis in a way that it contains \(\mathbf{v}\) as its new \(\mathbf{v}_1\), and change the other vectors in a way that they still form a basis of our lattice.</p>
<dl class="section remark"><dt>Remarks</dt><dd><b>Pierre</b>: Explain ow this can be done. Idea: The new basis vector \(\mathbf{v}\) is a linear combination of some old basis vectors \(\mathbf{v}_j\) and it will replace one of those vectors. Perhaps these old vectors need to be changed as well.</dd>
<dd>
<b>Pierre</b>: Give the complete algorithm around here.</dd></dl>
<p>Here is a pseudo-code for the Branch and Bound algorithm :</p>
<center><div class="LatSoft-fbox"><div class="image">
<img src="../../branchandbound.png" alt="branchandbound.png" width="700px"/>
<div class="caption">
Pseudo-code for the Branch-and-bound algorithm implemented in LatticeTester.</div></div>
 </div></center><p>The total time taken by this BB algorithm is roughly proportional to the number of tree nodes that we visit. One major drawback is that in the worst case, this number of nodes typically grows exponentially with the dimension. It is therefore important to reduce this number as much possible. For this, it helps to start with a basis in which \(\mathbf{v}_1\) is shorter, because this shortens the search interval determined by the bounds <a class="el" href="../../da/d18/a_intro.html#REF__eq_bounds">(bounds)</a> at each level \(j\), and can therefore greatly reduce the number of nodes that must be examined. Various heuristics discussed below help achieve this. For the same reason, it also helps it we quickly find a tree leaf that corresponds to an improved solution, because it can reduce (dynamically) the size of the tree. We found experimentally that searching the BB tree depth-first from the center is usually the most effective approach, because it permits one to find a shorter \(\mathbf{v}_1\) faster. That is, at each level \(j\), instead of scanning the interval for \(z_j\) from one size to the other, we scan it by starting with the \(z_j\) that is closest to 0, then we examine the second closest, etc. <b>Pierre</b>: Correct? With this procedure, the first visited branch corresponds to the trivial ``solution'' in which \(z_t = \cdots = z_1 = 0\), and this solution is rejected. The second visited branch corresponds to \(z_t = \cdots = z_2 = 0\) and \(z_1=1\), i.e., \(\mathbf{v} = \mathbf{v}_1\).</p>
<p>Observe that if \(\mathbf{v} = \mathbf{V}\mathbf{z}\) is a lattice vector, \(-\mathbf{v} = \mathbf{V}(-\mathbf{z})\) is also a lattice vector with exactly the same length. We can exploit this symmetry to cut the BB tree in half, simply by considering only non-negative values of \(z_1\). We can do that because any vector \(\mathbf{z}\) with \(z_1 &lt; 0\) has an equivalent vector \(-\mathbf{z}\) having \(z_1 &gt; 0\).</p>
<h2><a class="anchor" id="bb_prered"></a>
Pre-reduction heuristics</h2>
<p>We now describe some heuristics that can be applied to pre-reduce (shorten) the basis vectors before starting the BB algorithm. The computing time invested with these heuristics is usually profitable in small and moderate dimensions, and practically essential in large dimensions.</p>
<h3><a class="anchor" id="prered_dieter"></a>
Dieter pre-reduction</h3>
<p>It is simple heuristic discussed in <a class="el" href="../../d0/de3/citelist.html#CITEREF_rDIE75a">[4]</a> <a class="el" href="../../d0/de3/citelist.html#CITEREF_rKNU98a">[12]</a> also known as <em>pairwise reduction</em> method. It consists in trying to reduce the length of a basis vector \(\mathbf{v}_i\) by subtracting from it \(q\) times another basis vector \(\mathbf{v}_j\), for some integer \(q\) and given indices \(i\not=j\). One can easily verify that the Euclidean length of the new vector \(\mathbf{v} = \mathbf{v}_i - q \mathbf{v}_j\) is minimized by taking \(q = \lfloor \mathbf{v}_i^\mathbf{t}\mathbf{v}_j / \mathbf{v}_j^\mathbf{t} \mathbf{v}_j\rfloor\). If this \(q\) is nonzero, we can replace \(\mathbf{v}_i\) by the strictly shorter vector \(\mathbf{v}_i - q \mathbf{v}_j\) in the basis. If the dual basis is maintained, we must also replace \(\mathbf{w}_j\) by \(\mathbf{w}_j + q \mathbf{w}_i\) in the dual basis, so it remains consistent. This can be tried with all pairs \(i\not=j\), and repeated until running through all pairs gives no further improvement.</p>
<p>Pairwise reductions can also be applied to the dual basis. The motivation is that reducing the vectors of the dual basis often lead to a reduction of the vectors of the primal basis. Here we try to reduce the length of a dual basis vector \(\mathbf{w}_i\) by replacing this vector by \(\mathbf{w}_i - q \mathbf{w}_j\), where \(q = \lfloor \mathbf{w}_i^\mathbf{t} \mathbf{w}_j / \mathbf{w}_j^\mathbf{t} \mathbf{w}_j\rfloor\). If \(q\not=0\) and if the corresponding primal basis vector \(\mathbf{v}_j + q \mathbf{v}_i\) is not longer than \(\mathbf{v}_j\), then we make the replacement. This can also be tried for all pairs \(i\not=j\), and repeated until it gives no improvement. </p><dl class="section remark"><dt>Remarks</dt><dd>Pierre: I do not fully understand why this is effective, because this is exactly equivalent to a pairwise reduction in the primal basis with \(-q\) instead of \(q\). To be verified. <b>Marc-Antoine</b>: This is true and should be noted. Dieter says that from his experiments this works well. I think the idea is that we reduce both the primal and the dual basis this way, which is interesting in our use case. Maybe. Otherwise it might just be an empirical result that when we play between both the reduction is better. </dd>
<dd>
<b>Pierre</b>: Note: In the LatMRG software, the pairwise reductions are not performed exactly in this order.</dd></dl>
<h3><a class="anchor" id="prered_LLL"></a>
LLL pre-reduction</h3>
<p>Lenstra, Lenstra, and Lovasz <a class="el" href="../../d0/de3/citelist.html#CITEREF_mLEN82a">[20]</a> have proposed a popular form of lattice basis reduction known as <em>LLL reduction</em>. Our software implements/uses (in most cases we use the <a class="el" href="../../d2/d5a/namespaceNTL.html" title="This module contains extensions of certain classes in NTL. ">NTL</a> implementation) a slightly modified version of this algorithm presented in <a class="el" href="../../d0/de3/citelist.html#CITEREF_mSCH91a">[25]</a>.</p>
<p>Let us recall <em>Gram-Schmidt orthogonalization</em>. From the basis \(\{\mathbf{v}_1, \ldots, \mathbf{v}_t\}\), we can get an orthogonal basis \(\{\hat{\mathbf{v}}_1, \ldots, \hat{\mathbf{v}}_t\}\) by taking </p><p class="formulaDsp">
\[ \hat{\mathbf{v}}_1 = \mathbf{v}_1, \ \hat{\mathbf{v}}_i = \mathbf{v}_i - \sum_{j=1}^{i-1} \mu_{ij} \hat{\mathbf{v}}_j,\ \mu_{ij} = \frac{\mathbf{v}_i \cdot \hat{\mathbf{v}}_j}{\hat{\mathbf{v}}_j \cdot \hat{\mathbf{v}}_j} \]
</p>
<p> For a small \(0 \leq \epsilon &lt; 3/4\), we say that a basis is \(\epsilon\)-LLL reduced if</p>
<ol type="1">
<li>\( |\mu_{ij}| \leq 1/2 \) for \(1 \leq j &lt; i \leq t\) ;</li>
<li>for \(0 &lt; i \leq t-1 \), \(1-\epsilon \leq \frac{\Vert \hat{\mathbf{v}}_{i+1} + \mu_{i\,i+1} \hat{\mathbf{v}}_i \Vert^2}{\Vert \hat{\mathbf{v}}_i\Vert^2}\);</li>
</ol>
<p>Here, the first condition means that for any \(i \neq j\), it is not possible to reduce \(\mathbf{v}_i\) by adding to it an integer multiple of \(\mathbf{v}_j\). This is equivalent to one step of pairwise reduction in the primal. The second condition means that we want to sort the vectors so that \(\mathbf{v}_i\) is the vector with the shortest projection on \(\text{span}(\mathbf{v}_1, \ldots \mathbf{v}_{i-1})\) among \(\{\mathbf{v}_i, \ldots, \mathbf{v}_{t}\}\) (the condition does not make sure this is attained, but it is the idea behind it I think). Also note that in practice, we would like to take \(0&lt;\epsilon\) as small as possible.</p>
<p>This algorithm does a very simple <code>while</code> loop. From \(k=2\) it performs pairwise reduction of \(\mathbf{v}_k\) with \( \mathbf{v}_{k-1}, \ldots, \mathbf{v}_t\) and checks if the condition 2 is verified for \(i = k-1\). If it is, \(k\) is incremented. If it's not, \(\mathbf{v}_k\) and \(\mathbf{v}_{k-1}\) are swapped and \(k\) is decremented if it is greater than 2. Since the version we use has floating point arithmetic, it also has a few more steps to account for the possible error. Moreover, this algorithm can be expanded to take a generating set of more than \(t\) vectors of the lattice and still return a reduced basis (the last vectors in the reduced basis will be set to \(\mathbf{0}\)).</p>
<p>This particular reduction does not necessarily returns the shortest vector as \(\mathbf{v}_1\). However, we have that \( 1 \leq \Vert \mathbf{v}_1 \Vert^2 / \ell_t^2 \leq (3/4 - \epsilon)^{1-t}\) (<a class="el" href="../../d0/de3/citelist.html#CITEREF_mSCH91a">[25]</a>) and the lengths of the other basis vectors also not much larger than that of \(\mathbf{v}_1\) after the reduction.</p>
<p>For this reason, an LLL-reduced basis tends to yield a much thinner BB tree. Moreover, an \(\epsilon\)-LLL reduction can be performed quickly (it is polynomial in the number of dimensions if the arithmetic is exact but could cycle indefinitely if \(\epsilon\) is too close to 0 and the precision too small). It is therefore very effective and useful. Some authors fix \(\epsilon\) at 1/4 <a class="el" href="../../d0/de3/citelist.html#CITEREF_mHEL85a">[10]</a> <a class="el" href="../../d0/de3/citelist.html#CITEREF_mLOV86a">[21]</a>, but we prefer much smaller values. In our implementations, we use \(\epsilon = 10^{-6}\) as the default value.</p>
<h3><a class="anchor" id="prered_BKZ"></a>
BKZ pre-reduction</h3>
<p>The block Korkin-Zolotarev algorithm that we use is the one presented in <a class="el" href="../../d0/de3/citelist.html#CITEREF_mSCH91a">[25]</a> (the one used in <a class="el" href="../../d2/d5a/namespaceNTL.html" title="This module contains extensions of certain classes in NTL. ">NTL</a>). It is more costly than LLL, but it yields better results, leading to an accelerated <em>Branch and Bound</em> in some cases. This is basically a generalization of the LLL reduction using stronger parameters.</p>
<p>In LLL we want to sort the vectors so that \(\mathbf{v}_i\) is the vector with the shortest projection on \(\text{span}(\mathbf{v}_1, \ldots \mathbf{v}_{i-1})\) among \(\{\mathbf{v}_i, \ldots, \mathbf{v}_{t}\}\). BKZ is a stronger algorithm that allows us to get closer to this goal.</p>
<h3><a class="anchor" id="prered_precision"></a>
A note on precision</h3>
<p>We should say a few words on precision. Also, we should advise the user that if they only intend on using prereductions, they should only use <a class="el" href="../../d2/d5a/namespaceNTL.html" title="This module contains extensions of certain classes in NTL. ">NTL</a> because <em><a class="el" href="../../d8/d74/namespaceLatticeTester.html" title="Lattice namespace. ">LatticeTester</a></em> is just a wrapper most of the time. </p>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="../../index.html">LatticeTester Manual</a></li>
    <li class="footer">Generated on Mon Sep 10 2018 13:22:40 for Lattice Tester Manual by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="../../doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
